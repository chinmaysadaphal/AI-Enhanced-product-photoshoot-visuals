{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement \"AI-Enhanced Product Photoshoot Visuals and Filter\""
      ],
      "metadata": {
        "id": "6TJkuHYKarcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_cv"
      ],
      "metadata": {
        "id": "a2FoFeVKxatn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras_cv.models import StableDiffusion\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Cm8jFPjXl4RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VzCxu9xoyeug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Stable Diffusion model\n",
        "# take tectual prompt and give visual product\n",
        "model_diffusion = StableDiffusion(img_width=512, img_height=512)"
      ],
      "metadata": {
        "id": "YhZAekJIn1IL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained MobileNetV2 model for image classification\n",
        "# We load a pre-trained MobileNetV2 model from TensorFlow's applications module.\n",
        "# This model will be used for image classification.\n",
        "model_classification = tf.keras.applications.MobileNetV2(weights='imagenet')"
      ],
      "metadata": {
        "id": "eCL_-v5Tn29F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(prompt, batch_size=3):\n",
        "    # Generate images based on the prompt using Stable Deffusion model\n",
        "    images = model_diffusion.text_to_image(prompt, batch_size=batch_size)\n",
        "    return images\n"
      ],
      "metadata": {
        "id": "i8Bfu0EDzP7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(images):\n",
        "    # Plot the generated images\n",
        "    # function takes a list of images and plots them using matplotlib.\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    for i, image in enumerate(images):\n",
        "        ax = plt.subplot(1, len(images), i + 1)\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "abgatRkcoAsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_images(images):\n",
        "    # Resize images to match the input shape expected by MobileNetV2 (224x224)\n",
        "    resized_images = [tf.image.resize(img, (224, 224)) for img in images]\n",
        "    # Preprocess images for MobileNetV2\n",
        "    preprocessed_images = [tf.keras.applications.mobilenet_v2.preprocess_input(img) for img in resized_images]\n",
        "    preprocessed_images = np.array(preprocessed_images)\n",
        "    return preprocessed_images"
      ],
      "metadata": {
        "id": "uCBde93eoGzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_images(images, model):\n",
        "    # Preprocess and resize images\n",
        "    preprocessed_images = preprocess_images(images)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(preprocessed_images)\n",
        "\n",
        "    # Decode predictions\n",
        "    # the MobileNetV2 model converts the raw predictions (typically a list of class probabilities) into a list of tuples,\n",
        "    # where each tuple contains the ImageNet class ID, label, and probability score for each image.\n",
        "\n",
        "    decoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(predictions)\n",
        "    return decoded_predictions"
      ],
      "metadata": {
        "id": "6dKfqn-LoKir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_non_relevant_images(images, model):\n",
        "    # Implement a binary classifier for demonstration\n",
        "\n",
        "    relevant_images = []\n",
        "    for image in images:\n",
        "        # Use the MobileNetV2 model for binary classification\n",
        "        preprocessed_image = preprocess_images([image])\n",
        "        prediction = model.predict(preprocessed_image)#check weather image is relevent or not\n",
        "\n",
        "        # Modify this condition based on your binary classification model\n",
        "        if prediction[0][0] > 0.5:\n",
        "            relevant_images.append(image)\n",
        "\n",
        "    return relevant_images"
      ],
      "metadata": {
        "id": "PIMswVq02dEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "#prompt = \"Car\"\n",
        "#batch_size = 3\n",
        "\n",
        "import random\n",
        "entities = [\n",
        "    \"Shoe\", \"Sneaker\", \"Bottle\", \"Cup\", \"Sandal\", \"Perfume\", \"Toy\", \"Sunglasses\",\n",
        "    \"Car\", \"Water Bottle\", \"Chair\", \"Office Chair\", \"Can\", \"Cap\", \"Hat\",\n",
        "    \"Couch\", \"Wristwatch\", \"Glass\", \"Bag\", \"Handbag\", \"Baggage\", \"Suitcase\",\n",
        "    \"Headphones\", \"Jar\", \"Vase\"\n",
        "]\n",
        "\n",
        "def select_entity():\n",
        "     return random.choice(entities)\n",
        "if __name__ == \"__main__\":\n",
        "     chosen_entity = select_entity()\n",
        "     print(\"Chosen entity:\", chosen_entity)\n",
        "prompt=chosen_entity\n",
        "batch_size=2"
      ],
      "metadata": {
        "id": "Qk-J10SDoNO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and plot images\n",
        "generated_images = generate_images(prompt, batch_size=batch_size)\n",
        "relevant_images = filter_non_relevant_images(generated_images, model_classification)\n",
        "plot_images(generated_images)"
      ],
      "metadata": {
        "id": "dWsxdlscoQvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ny_lz8lU3QDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify generated images\n",
        "classifications = classify_images(generated_images, model_classification)"
      ],
      "metadata": {
        "id": "Vo2wRgB4oU0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = []\n",
        "for i, img_class in enumerate(classifications):\n",
        "    top_prediction = img_class[0]  # Get the top predicted class\n",
        "    _, true_label, _ = top_prediction  # Extract the true label from the top prediction\n",
        "    _, predicted_label, score = classifications[i][0]  # Extract the predicted label and score\n",
        "\n",
        "    if true_label.lower() in prompt.lower():\n",
        "        accuracy = score  # Use confidence score as accuracy if true label is in the prompt\n",
        "    else:\n",
        "        accuracy = 1 - score  # Invert confidence score as accuracy if true label is not in the prompt\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    # Print the classification result including accuracy\n",
        "    print(f\"Image {i + 1} classification (Accuracy: {accuracy:.2f}):\")\n",
        "    for j, (imagenet_id, label, score) in enumerate(img_class):\n",
        "        print(f\"{j + 1}: {label} ({score:.2f})\")\n",
        "    print()\n",
        "\n",
        "# Print the average accuracy\n",
        "average_accuracy = sum(accuracies) / len(accuracies)\n",
        "print(f\"Average Accuracy: {average_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "oinZ_K1q8nXj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}